---
title: Troubleshooting MySQL for PCF
owner: MySQL
---

<p class="note warning"><strong>Warning:</strong> <%= vars.first_product_name %> 
	v<%= product_info['local_product_version'] %> is no longer supported 
because it has reached the End of General Support (EOGS) phase.
To stay up to date with the latest software and security updates,
upgrade to a supported version.
</p>

<strong><%= modified_date %></strong>

<div>
  <ul>
    <li><a href="#errors">Troubleshooting Errors</a>
      <ul>
        <li><a href="#install-fail">Failed Install</a></li>
        <li><a href="#cannot-create-delete">Cannot Create or Delete Service Instances</a></li>
        <li><a href="#timeouts">Broker Request Timeouts</a></li>
        <li><a href="#cannot-bind">Cannot Bind to or Unbind from Service Instances</a></li>
        <li><a href="#cannot-connect">Cannot Connect to a Service Instance</a></li>
        <li><a href="#upgrade-all-fails">Upgrade All Instances Fails</a></li>
        <li><a href="#missing-logs">Missing Logs and Metrics</a></li>
        <li><a href="#unable-to-determine">Unable to Determine Leader and Follower (Errand Error)</a></li>
        <li><a href="#both-writable">Both Leader and Follower Instances Are Writable (Errand Error)</a></li>
        <li><a href="#both-read-only">Both Leader and Follower Instances Are Read-Only</a></li>
        <li><a href="#persistent-disk">Persistent Disk is Full</a></li>
      </ul>
    </li>
    <li><a href="#components">Troubleshooting Components</a>
      <ul>
        <li><a href="#bosh">BOSH Problems</a></li>
        <li><a href="#bosh-config">Configuration</a></li>
        <li><a href="#auth">Authentication</a></li>
        <li><a href="#network">Networking</a></li>
        <li><a href="#quotas">Quotas</a></li>
        <li><a href="#failing-jobs">Failing Jobs and Unhealthy Instances</a></li>
        <li><a href="#az-region-fail">AZ or Region Failure</a></li>
      </ul>
    </li>
    <li><a href="#techniques">Techniques for Troubleshooting</a>
      <ul>
        <li><a href="#parse-error">Parse a Cloud Foundry (CF) Error Message</a></li>
        <li><a href="#bosh-cf-access">Access Broker and Instance Logs and VMs</a></li>
        <li><a href="#broker-errands">Run Service Broker Errands to Manage Brokers and Instances</a></li>
        <li><a href="#detect-orphans">Detect Orphaned Service Instances</a></li>
        <li><a href="#instance-creds">Retrieve Admin and Read-Only Admin Credentials for a Service Instance</a></li>
        <li><a href="#reinstall">Reinstall a Tile</a></li>
        <li><a href="#view-resources">View Resource Saturation and Scaling</a></li>
        <li><a href="#id-instance-owner">Identify Service Instance Owner</a></li>
        <li><a href="#monitor-quota">Monitor Quota Saturation and Service Instance Count</a></li>
      </ul>
    </li>
    <li><a href="#kb">Knowledge Base (Community)</a></li>
    <li><a href="#support">File a Support Ticket</a></li>
  </ul>
</div>

This topic provides operators with basic instructions for troubleshooting on-demand MySQL for PCF.

For information on temporary MySQL for PCF service interruptions, see <a href="./upgrade.html#interruptions">Service Interruptions</a>.

<a id="errors"></a><h2>Troubleshooting Errors</h2>

This section provides information on how to troubleshooting specific errors or error messages.

<a id="install-fail"></a><h3>Failed Install</h3>

Reasons for a failed <%=vars.service_name %> installation include:

<ol>
  <li>
    Certificate issues: The on-demand broker (ODB) requires valid certificates.
    Ensure that your certificates are valid and generate new ones if necessary.
    To generate new certificates, contact <a href="https://support.pivotal.io">Pivotal Support</a>.
  </li>
  <li>Deploy fails: Deploys can fail for a variety of reasons.
    View the logs using Ops Manager to determine why the deploy is failing.
  </li>
  <li><a href="#network">Networking problems</a>: </li>
  <ul>
    <li>Cloud Foundry cannot reach <%=vars.service_name_article_full%> broker</li>
    <li>Cloud Foundry cannot reach the service instances</li>
    <li>The service network cannot access the BOSH director </li>
  </ul>
  <li>The <a href="#register-broker">Register broker errand</a> fails.</li>
  <li>The smoke test errand fails.</li>
  <li>
    Resource sizing issues: These occur when the resource sizes selected for a
    given plan are less than <%=vars.service_name_article_full%> requires to function.
    Check your resource configuration in Ops Manager and ensure that the
    configuration matches that recommended by the service.
  </li>
  <li>Other service-specific issues.</li>
</ol>
<a id="cannot-create-delete"></a><h3>Cannot Create or Delete Service Instances</h3>

<p>
	If developers report errors such as:
</p>

<pre class="terminal">
Instance provisioning failed: There was a problem completing your request. Please contact your operations team providing the following information: service: redis-acceptance, service-instance-guid: ae9e232c-0bd5-4684-af27-1b08b0c70089, broker-request-id: 63da3a35-24aa-4183-aec6-db8294506bac, task-id: 442, operation: create
</pre>

<p>
	Follow these steps:
</p>

<ol>
	<li>
		<p>
			If the BOSH error shows a problem with the deployment manifest, open the
			manifest in a text editor to inspect it.
		</p>
	</li>
	<li>
		<p>
			To continue troubleshooting,
			<a href="https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#log-in">Log in to BOSH</a>
			and target <%= vars.service_name_article_full %> instance using the instructions
			on <a href="#parse-error">parsing a Cloud Foundry error message</a>.
		</p>
	</li>
	<li>
		<p>
			Retrieve the BOSH task ID from the error message and run the following command:
		</p>
		<pre><code>bosh task TASK-ID</code></pre>
	</li>
	<li>
		<p>
			If you need more information, <a href="#access-broker">access the broker logs</a> and
			use the <code>broker-request-id</code> from the error message above to search the logs for
			more information. Check for:
		</p>
	</li>
	<ul>
		<li><a href="#auth">Authentication errors</a></li>
		<li><a href="#network">Network errors</a></li>
		<li><a href="#quotas">Quota errors</a></li>
	</ul>
</ol>
<a id="timeouts"></a><h3>Broker Request Timeouts</h3>

<p>
	If developers report errors such as:
</p>

<pre class="terminal">
Server error, status code: 504, error code: 10001, message: The request to the service broker timed out: https://BROKER-URL/v2/service_instances/e34046d3-2379-40d0-a318-d54fc7a5b13f/service_bindings/aa635a3b-ef6d-41c3-a23f-55752f3f651b
</pre>

<p>
	Follow these steps:
</p>

<ol>
	<li>
		Confirm that Cloud Foundry (CF) is <a href="#network">connected to the service broker</a>.
	</li>
	<li>
		Check the BOSH queue size:
		<ol>
			<li>Log into BOSH as an admin.</li>
			<li>Run <code>bosh tasks</code>.</li>
		</ol>
	</li>
	<li>
		If there are a large number of queued tasks, the system may be under too much load.
		BOSH is configured with two workers and one status worker, which may not be
		sufficient resources for the level of load.
		Advise app developers to try again once the system is under less load.
	</li>
</ol>
<a id="cannot-bind"></a><h3>Cannot Bind to or Unbind from Service Instances</h3>

<a id="instance-not-exist"></a><h4>Instance Does Not Exist</h4>

<p>
	If developers report errors such as:
</p>

<pre class="terminal">
Server error, status code: 502, error code: 10001, message: Service broker error: instance does not exist`
</pre>

<p>
	Follow these steps:
</p>

<ol>
	<li>
		<p>
			Confirm that <%=vars.service_name_article_full%> instance exists in BOSH and
			obtain the GUID CF by running:
		</p>
		<pre><code>cf service MY-INSTANCE --guid</code></pre>
	</li>
	<li>
		<p>
			Using the GUID obtained above, the following BOSH CLI command:
		</p>
		<pre><code>bosh -d service-instance_GUID vms</code></pre>
	</li>
</ol>

<p>
	If the BOSH deployment is not found, it has been deleted from BOSH.
	Contact Pivotal support for further assistance.
</p>
<a id="other-errors"></a><h4>Other Errors</h4>

<p>
  If developers report errors such as:
</p>

<pre class="terminal">
Server error, status code: 502, error code: 10001, message: Service broker error: There was a problem completing your request. Please contact your operations team providing the following information: service: example-service, service-instance-guid: 8d69de6c-88c6-4283-b8bc-1c46103714e2, broker-request-id: 15f4f87e-200a-4b1a-b76c-1c4b6597c2e1, operation: bind
</pre>

<p>
  To find out the exact issue with the binding process:
</p>

<ol>
  <li>
    <p>
      <a href="#access-broker">Access the service broker logs</a>.
    </p>
  </li>
  <li>
    <p>
      Search the logs for the <code>broker-request-id</code> string listed in the error message above.
    </p>
  </li>
  <li>
    <p>
      Contact Pivotal support for further assistance if you are unable to resolve the problem.
    </p>
  </li>
  <li>
    <p>
      Check for:
    </p>
  </li>
  <ul>
    <li><a href="#auth">Authentication errors</a></li>
    <li><a href="#network">Network errors</a></li>
  </ul>
</ol>
<a id="cannot-connect"></a><h3>Cannot Connect to a Service Instance</h3>

<p>
  If developers report that their app cannot use service instances that they have
  successfully created and bound:
</p>

<p>
  Ask the user to send application logs that show the connection error.
  If the error is originating from the service, then follow <%=vars.service_name%>-specific instructions.
  If the issue appears to be network-related, then:
</p>

<ol>
  <li>
    <p>
      Check that <a href="https://docs.pivotal.io/pivotalcf/adminguide/app-sec-groups.html">application security groups</a>
      are configured correctly.
      Access should be configured for the service network that the tile is deployed to.
    </p>
  </li>
  <li>
    <p>
      Ensure that the network the <%= vars.app_runtime_full %> tile is deployed
      to has network access to the service network. You can find the network definition
      for this service network in the BOSH Director tile.
    </p>
  </li>
  <li>
    <p>
      In Ops Manager go into the service tile and see the service network that is
      configured in the networks tab.
    </p>
  </li>
  <li>
    <p>
      In Ops Manager go into the <%= vars.app_runtime %> tile and see the network it is assigned to.
      Make sure that these networks can access each other.
    </p>
  </li>
</ol>
Service instances can also become temporarily inaccessible during upgrades and VM or network failures. See <a href="./upgrade.html#interruptions">Service Interruptions</a> for more information.

<a id="upgrade-all-fails"></a><h3>Upgrade All Instances Fails</h3>

<p>
  If the <a href="#upgrade-all"><code>upgrade-all-service-instances</code></a> errand fails,
  look at the errand output in the Ops Manager log.
</p>

<p>
  If an instance fails to upgrade, debug and fix it before running the errand again
  to prevent any failure issues from spreading to other on-demand instances.
</p>

<p>
  Once the Ops Manager log no longer lists the deployment as <code>failing</code>,
  <a href="#upgrade-all">re-run the errand</a> to upgrade the rest of the instances.
</p>
<a id="missing-logs"></a><h3>Missing Logs and Metrics</h3>

<p>
  If no logs are being emitted by the on-demand broker, check that your syslog
  forwarding address is correct in Ops Manager.
</p>

<ol>
  <li>
    <p>
      Ensure you have configured syslog for the tile.
    </p>
  </li>
  <li>
    <p>
      Ensure that you have network connectivity between the networks that the tile
      is using and the syslog destination.
      If the destination is external, you need to use the <a href="https://docs.pivotal.io/svc-sdk/odb/tile.html#public-ip">public ip</a>
      VM extension feature available in your Ops Manager tile configuration settings.
    </p>
  </li>
  <li>
    <p>
      Verify that Loggregator is emitting metrics:
    </p>
    <ol>
      <li>
        <p>
          Install the <code>cf log-stream</code> plugin.
          For instructions, see the <a href="https://github.com/cloudfoundry/log-stream-cli">Log Stream CLI Plugin</a>
          GitHub repository.
        </p>
      </li>
      <li>
        <p>
          Find the GUID for your service instance by running:
        </p>
        <p>
          <pre><code>cf service SERVICE-INSTANCE --guid</code></pre>
        </p>
      </li>
      <li>
        <p>
          Find logs from your service instance by running:
        </p>
        <p>
          <pre><code>cf log-stream | grep "SERVICE-GUID"</code></pre>
        </p>
      </li>
    </ol>
  </li>
</ol>

<p>
  If no metrics appear within five minutes, verify that the broker network has access
  to the Loggregator system on all required ports.
</p>

<p>
  <a href="#support">Contact Pivotal support</a> if you are unable to resolve the issue.
</p>
<a id="unable-to-determine"></a><h3>Unable to Determine Leader and Follower (Errand Error)</h3>

This problem happens when the <code>configure-leader-follower</code> errand fails because it cannot determine the VM roles.

<h4>Symptom</h4>
The <code>configure-leader-follower</code> errand exits with <code>1</code> and the errand logs contain the following:

<pre class="terminal">$ Unable to determine leader and follower based on transaction history.</pre>

<h4>Explanation</h4>
Something has happened to the instances, such as a failure or manual intervention. As a result, there is not enough
information available to determine the correct state and topology without operator intervention to resolve the issue.

<h4>Solution</h4>

Use the <code>inspect</code> errand to determine which instance should be the leader. Then, using the <a href="./about-leader-follower.html#errands">orchestration</a> errands and backup/restore, you can
put the service instance into a safe topology, and then rerun the <code>configure-leader-follower</code> errand. This is shown in the example below.

This example shows one outcome that the <code>inspect</code> errand can return:

<ol>
  <li>Use the <code>inspect</code> errand to retrieve relevant information about the two VMs:
  <pre class="terminal">
  $ bosh -e my-env -d my-dep run-errand inspect
  [...]
  Instance   mysql/4ecad54b-0704-47eb-8eef-eb228cab9724
  Exit Code  0
  Stdout     -
  Stderr     2017/12/11 18:25:54 Started executing command: inspect
           2017/12/11 18:25:54 Started GET https<span>:</span>//127.0.0.1:8443/status
           2017/12/11 18:25:54
           Has Data: false
           Read Only: true
           GTID Executed: 1d774323-de9e-11e7-be01-42010a001014:1-25
           Replication Configured: false<br /><br />
  Instance   mysql/e0b94ade-0114-4d49-a929-ce1616d8beda
  Exit Code  0
  Stdout     -
  Stderr     2017/12/11 18:25:54 Started executing command: inspect
           2017/12/11 18:25:54 Started GET https<span>:</span>//127.0.0.1:8443/status
           2017/12/11 18:25:54
           Has Data: true
           Read Only: true
           GTID Executed: 1d774323-de9e-11e7-be01-42010a001014:1-25
           Replication Configured: true<br /><br />
  2 errand(s)<br />
  Succeeded
  </pre>
  In the above scenario, the first instance is missing data but does not have replication configured. The second instance
  has data, and also has replication configured. The instructions below resolve this by copying data to the first instance,
  and resuming replication.</li>
  <li>Take a backup of the second instance using the <a href="backup-and-restore.html#manual-backup">Manual Backup</a> steps.</li>
  <li>Restore the backup artifact to the first instance using the <a href="backup-and-restore.html#restore">Manual Restore</a> steps.<br><br>
  	At this point, the instances have equivalent data.</li>
  <li> Run the <code>configure-leader-follower</code> errand to reconfigure replication:
  <code> bosh -e ENVIRONMENT -d DEPLOYMENT run-errand configure-leader-follower --instance=mysql/GUID-OF-LEADER </code>
  <pre class="terminal">
  $ bosh -e my-env -d my-dep \
    run-errand configure-leader-follower \
    --instance=mysql/4ecad54b-0704-47eb-8eef-eb228cab9724
  </pre></li>
</ol>

<h3><a id="both-writable"></a>Both Leader and Follower Instances Are Writable (Errand Error)</h3>

This problem happens when the <code>configure-leader-follower</code> errand fails
because both VMs are writable and the VMs might hold differing data.

<h4>Symptom</h4>

The <code>configure–leader-follower</code> errand exits with <code>1</code> and the errand logs contain the following:<br><br>

<pre class="terminal">$ Both mysql instances are writable. Please ensure no divergent data and set one instance to read-only mode.</pre>

<h4>Explanation</h4>

MySQL for PCF tries to ensure that there is only one writable instance of the leader-follower pair at any given time.
However, in certain situations, such as
network partitions, or manual intervention outside of the provided bosh errands, it is possible for both instances
to be writable.

The service instances remain in this state until an operator resolves the issue to ensure that the correct instance is
promoted and reduce the potential for data divergence.

<h4>Solution</h4>

<ol>
<li> Use the <code>inspect</code> errand to retrieve the GTID Executed set for each VM:
<pre class="terminal">
$ bosh -e my-env -d my-dep run-errand inspect
[...]
Instance   mysql/4ecad54b-0704-47eb-8eef-eb228cab9724
Exit Code  0
Stdout     -
Stderr     2017/12/11 18:25:54 Started executing command: inspect
         2017/12/11 18:25:54 Started GET https<span>:</span>127.0.0.1:8443/status
         2017/12/11 18:25:54
         Has Data: true
         Read Only: false
         GTID Executed: 1d774323-de9e-11e7-be01-42010a001014:1-23
         Replication Configured: false<br /><br />
Instance   mysql/e0b94ade-0114-4d49-a929-ce1616d8beda
Exit Code  0
Stdout     -
Stderr     2017/12/11 18:25:54 Started executing command: inspect
         2017/12/11 18:25:54 Started GET https<span>:</span>127.0.0.1:8443/status
         2017/12/11 18:25:54
         Has Data: true
         Read Only: false
         GTID Executed: 1d774323-de9e-11e7-be01-42010a001014:1-25
         Replication Configured: false<br /><br />
2 errand(s)<br />
Succeeded
</pre>
If the GTID Executed sets for both instances are the same, continue to Step 2. If they are different, continue to Step 4.</li>
<li>Look at the value of GTID Executed for both instances.
    <ul><li>If the range after the GUID is equivalent, either instance can be made read-only, as described in Step 3.</li>
    <li>If one instance has a range that is a subset of the other, the instance with the subset should be made read-only, as
      described in Step 3.</li></ul></li>
<li>Based on the information you gathered in the step above, run the <code>make-read-only</code> errand to make the appropriate instance read-only:
<code> bosh -e ENVIRONMENT -d DEPLOYMENT run-errand make-read-only --instance=mysql/MYSQL-SUBSET-INSTANCE
</code>
<pre class="terminal">
$ bosh -e my-env -d my-dep \
  run-errand make-read-only \
  --instance=mysql/e0b94ade-0114-4d49-a929-ce1616d8beda
[...]
Succeeded
</pre></li>
<li>If the GTID Executed sets are neither equivalent nor subsets,
   data has diverged and you must determine what data has diverged as part of the procedure below:
   <ol>
	<li>Use the <code>make-read-only</code> errand to set both instances to read-only to prevent further data divergence.
    <code> bosh -e ENVIRONMENT -d DEPLOYMENT run-errand make-read-only --instance=mysql/MYSQL-INSTANCE </code>
<pre class="terminal">$ bosh -e my-env -d my-dep \
  run-errand make-read-only \
  --instance=mysql/e0b94ade-0114-4d49-a929-ce1616d8beda
[...]
Succeeded</pre></li>
	<li>Take a backup of both instances using the <a href="backup-and-restore.html#manual-backup">Manual Backup</a> steps.</li>
	<li>Manually inspect the data on each instance to determine the discrepancies and put the data on the instance that is
    further ahead---this instance has the higher GTID Executed set, and will be the new leader.</li>
	<li>Migrate all appropriate data to the new leader instance.</li>
	<li>After putting all data on the leader, ssh onto the follower:
    <code> bosh -e ENVIRONMENT -d DEPLOYMENT ssh mysql/GUID-OF-FOLLOWER</code>
<pre class="terminal">$ bosh -e my-env -d my-dep ssh mysql/e0b94ade-0114-4d49-a929-ce1616d8beda</pre></li>
	<li>Become root with the command <code>sudo su</code>.<br></li>
	<li>Stop the mysql process with the command <code>monit stop mysql</code>.</li>
	<li>Delete the data directory of the follower with the command <code>rm -rf /var/vcap/store/mysql</code>.</li>
	<li>Start the mysql process with the command <code>monit start mysql</code>.</li>
	<li>Use the <code>configure-leader-follower</code> errand to copy the leader's data to the follower and resume replication:
    <code> bosh -e ENVIRONMENT -d DEPLOYMENT run-errand configure-leader-follower --instance=mysql/GUID-OF-LEADER</code>
<pre class="terminal">$ bosh -e my-env -d my-dep \
  run-errand configure-leader-follower \
  --instance=mysql/4ecad54b-0704-47eb-8eef-eb228cab9724</pre></li>
</ol>
</li>
</ol>

<h3><a id="both-read-only"></a>Both Leader and Follower Instances Are Read-Only</h3>

In a leader-follower topology, the leader VM is writable and
the follower VM is read-only. However if both VMs are read only, apps cannot write to the database.


<h4>Symptom</h4>

Developers report that apps cannot write to the database.

<h4>Explanation</h4>

This problem happens if the leader VM fails and the BOSH Resurrector is enabled.
When the leader is resurrected, it is set as read-only.


<h4>Solution</h4>

<ol>
    <li> Use the <code>inspect</code> errand to confirm that both VMs are in a read-only state:
        <code>
            bosh -e ENVIRONMENT -d DEPLOYMENT run-errand inspect
        </code>
    </li>
    <li>Examine the output and locate the information about the leader-follower MySQL VMs:
<pre class="terminal">
Instance   mysql/4eexample54b-0704-47eb-8eef-eb2example724
Exit Code  0
Stdout     -
Stderr     2017/12/11 18:25:54 Started executing command: inspect
         2017/12/11 18:25:54 Started GET https<span>:</span>999.0.0.1:8443/status
         2017/12/11 18:25:54
         Has Data: true
         Read Only: true
         GTID Executed: 1d779999-de9e-11e7-be01-42010a009999:1-23
         Replication Configured: true<br /><br />
Instance   mysql/e0exampleade-0114-4d49-a929-cexample8beda
Exit Code  0
Stdout     -
Stderr     2017/12/11 18:25:54 Started executing command: inspect
         2017/12/11 18:25:54 Started GET https<span>:</span>999.0.0.1:8443/status
         2017/12/11 18:25:54
         Has Data: true
         Read Only: true
         GTID Executed: 1d779999-de9e-11e7-be01-42010a009999:1-25
         Replication Configured: false<br /><br />
2 errand(s)<br />
Succeeded
</pre>
    </li>
    <li>
        If Read Only is set to <code>true</code> for both VMs, make the leader writable using the following command:
        <code>bosh -e ENVIRONMENT -d DEPLOYMENT run-errand configure-leader-follower --instance=mysql/GUID-OF-LEADER</code>
        <br><br>For example, if the second instance above is the leader:
<pre class="terminal">
$ bosh -e my-env -d my-dep \
  run-errand configure-leader-follower \
  --instance=mysql/e0exampleade-0114-4d49-a929-cexample8beda
</pre>
    </li>
</ol>

<h3><a id="persistent-disk"></a>Persistent Disk is Full</h3>

If your persistent disk is full, apps become inoperable. In this state, read,
write, and Cloud Foundry Command-Line Interface (cf CLI) operations do not work.

<h4>Symptom</h4>

Developers report that read, write, and cf CLI operations do not work.
Developers cannot upgrade to a larger MySQL service plan to free up disk space.

<h4>Explanation</h4>

This problem happens if your persistent disk is full. When you use the BOSH CLI to
target your deployment, you see that instances are at 100% persistent disk
usage.
<br><br>
Available disk space can be increased by deleting audit log files.
After deleting audit logs, you can then upgrade to a larger MySQL service plan.

<h4>Solution</h4>
<ol>
  <li> To retrieve and record the GUID of your service instance , run the
    following command:
    <br>
    <code>cf service SERVICE-INSTANCE-NAME --guid</code>
    <br><br>
    Where <code>SERVICE-INSTANCE-NAME</code> is the name of your service instance.
    <br><br>
    For example:
    <pre class="terminal">$ cf service my-service-instance --guid
    12345678-90ab-cdef-1234-567890abcdef</pre>
    If you do not know the name of your service instance, you can list service
    instances in the space with <code>cf services</code>.</pre>
  </li>

  <li> To confirm that your persistent disk usage is at 100%, run the following
    command:
    <br>
    <code>bosh -d service-instance_SERVICE-INSTANCE-GUID instances --vitals</code>
    <br><br>
    Where <code>SERVICE-INSTANCE-GUID</code> is the GUID you recorded in the
    above step.<br><br>
    For example:
      <pre class="terminal"> $bosh -d service-instance_12345678-90ab-cdef-1234-567890abcdef instances --vitals
Using environment 'https<span>:</span>//10.0.0.6:25555' as client 'admin'

Task 19243. Done

Deployment 'service-instance_12345678-90ab-cdef-1234-567890abcdef'

Instance                                    Process State  AZ  IPs         VM Created At                 Uptime           Load              CPU    CPU    CPU   CPU   Memory        Swap      System      Ephemeral   Persistent
                                                                                                                          (1m, 5m, 15m)     Total  User   Sys   Wait  Usage         Usage     Disk Usage  Disk Usage  Disk Usage
mysql/ca0ed8b5-7590-4cde-bba8-7ca2935f2bd0  running        z3  10.0.18.20  Wed Sep 12 22:01:44 UTC 2018  35d 20h 54m 17s  0.02, 0.03, 0.00  -      10.2%  0.4%  0.2%  14% (1.1 GB)  0% (0 B)  54% (37i%)  11% (4i%)   7% (0i%)

1 instances

Succeeded
  </li>

  <li>
    To retrieve and record the instance ID of your service instance, follow the
    procedure below that correponds with your VM topology.
    <ul>
    <li>If you are using single node MySQL VMs, to retrieve and record the
      instance ID, run the
    following command:
    <br>
    <code>bosh -d service-instance_SERVICE-INSTANCE-GUID instances</code>
    <br><br>
    Where <code>SERVICE-INSTANCE-GUID</code> is the GUID you recorded in
    step 1.<br>
    <br>
    For example:
    <pre class="terminal">$ bosh -d service-instance_12345678-90ab-cdef-1234-567890abcdef
      instances
      Using environment '34.237.123.534' as client 'admin'

      Task 204. Done

      Deployment 'service-instance_12345678-90ab-cdef-1234-567890abcdef'

      Instance                                    Process State  AZ  IPs
      mysql/ca0ed8b5-7590-4cde-bba8-7ca2935f2bd0  running        z2  10.244.17.3

      1 instances

      Succeeded
    </pre>

  The instance ID is the value for <code>Instance</code> after <code>mysql/</code>.
  <br><br>
  In the above output, the instance ID of the leader VM is <code>d15419ba-fc6c-4013-b056-19f91c6b0f1d</code>.
  <br><br>
</li>
  <li>If you are using leader-follower MySQL VMs, to retrieve and record the
    leader instance ID, run the
  following command:
  <br>
  <code>bosh -d service-instance_SERVICE-INSTANCE-GUID run-errand inspect</code>
  <br><br>
  Where <code>SERVICE-INSTANCE-GUID</code> is the GUID you recorded in the
  step one.<br>
  <br>
  For example:
  <pre class="terminal">
  $ bosh -d service-instance_12345678-90ab-cdef-1234-567890abcdef run-errand inspect
  Instance   mysql/ca0ed8b5-7590-4cde-bba8-7ca2935f2bd0
  Exit Code  0
  Stdout     2018/04/03 18:08:46 Started executing command: inspect
            2018/04/03 18:08:46
            IP Address: 10.0.8.11
            Role: leader
            Read Only: false
            Replication Configured: false
            Replication Mode: async
            Has Data: true
            GTID Executed: 82ddc607-710a-404e-b1b8-a7e3ea7ec063:1-18
            2018/04/03 18:08:46 Successfully executed command: inspect
  Stderr     -
  <br>
  Instance   mysql/37e4b6bc-2ed6-4bd2-84d1-e59a91f5e7f8
  Exit Code  0
  Stdout     2018/04/03 18:08:46 Started executing command: inspect
            2018/04/03 18:08:46
            IP Address: 10.0.8.10
            Role: follower
            Read Only: true
            Replication Configured: true
            Replication Mode: async
            Has Data: true
            GTID Executed: 82ddc607-710a-404e-b1b8-a7e3ea7ec063:1-18
            2018/04/03 18:08:46 Successfully executed command: inspect
  </pre>
   The leader instance ID is the value for <code>Instance</code>
   after <code>mysql/</code> corresponding with the instance marked <code>Role: leader</code> .
   <br><br>
   In the above output, the instance ID of the leader VM is <code>ca0ed8b5-7590-4cde-bba8-7ca2935f2bd0</code>.
 </li>
</ul>
  </li>

  <li> To BOSH SSH into your service instances, run the following command:
  <br>
  <code>bosh -d service-instance_SERVICE-INSTANCE-GUID ssh mysql/INSTANCE-ID</code>
  <br><br>
  Where:
  <br>
  <ul>
    <li> <code>SERVICE-INSTANCE-GUID</code> is the GUID you recorded in
      step 1.</li>
    <li> <code>INSTANCE-ID</code> is the instance ID you recorded in the
      above step. </li>
    <br>
    For example:
    <pre class="terminal">
      $ bosh -d service-instance_12345678-90ab-cdef-1234-567890abcdef ssh mysql/ca0ed8b5-7590-4cde-bba8-7ca2935f2bd0
      Using environment 'https:<span>//10.0.0.6:25555</span>' as client 'admin'

      Using deployment 'service-instance_12345678-90ab-cdef-1234-567890abcdef'

      Task 19244. Done
    </pre>
  </ul>
  <li> To move to the directory where your audit log files are located, run the
  following command:
  <br>
  <code>cd /var/vcap/sys/log/mysql/mysql-audit-log</code>
  </li>
  <li> Delete at least one audit log file with <code>rm</code> </li>

  <li> Update your service instance to a larger plan. For more information,
    see <a href= "./use.html#update">Update a Service Instance to a Larger Plan</a> </li>

<a id="components"></a><h2>Troubleshooting Components</h2>

This section provides guidance on checking for and fixing issues in on-demand service components.

<a id="bosh"></a><h3>BOSH Problems</h3>

<a id="large-queue"></a><h4>Large BOSH Queue</h4>

<p>
  On-demand service brokers add tasks to the BOSH request queue, which can back up
  and cause delay under heavy loads.
  An app developer who requests a new <%=vars.service_name%> instance sees
  <code>create in progress</code> in the Cloud Foundry Command Line Interface (cf CLI) until
  BOSH processes the queued request.
</p>

<p>
  Ops Manager currently deploys two BOSH workers to process its queue.
  Future versions of Ops Manager will let users configure the number of BOSH workers.
</p>
<a id="bosh-config"></a><h3>Configuration</h3>

<a id="bosh-instance-fail"></a><h4>Service instances in failing state</h4>

<p>
  You may have configured a VM / Disk type in tile plan page in Ops Manager that
  is insufficiently large for <%=vars.service_name_article_full%> instance to start.
  See tile-specific guidance on resource requirements.
</p>
<a id="auth"></a><h3>Authentication</h3>

<a id="uaa-change"></a><h4>UAA Changes</h4>

<p>
	If you have rotated any UAA user credentials then you may see authentication
	issues in the service broker logs.
</p>

<p>
	To resolve this, redeploy the <%=vars.service_name%> tile in Ops Manager.
	This provides the broker with the latest configuration.
</p>

<p class="note">
    <strong>Note</strong>: You must ensure that any changes to UAA
    credentials are reflected in the Ops Manager <code>credentials</code>
    tab of the <%= vars.app_runtime_full %> tile.
</p>
<a id="network"></a><h3>Networking</h3>

<p>
	Common issues with networking include:
</p>

<table class="nice">
	<col width="50%">
	<col width="50%">
	<th>Issue</th>
	<th>Solution</th>
	<tr>
		<td>Latency when connecting to <%=vars.service_name_article_full%> instance to create or delete a binding.</td>
		<td>Try again or improve network performance.</td>
	</tr>
	<tr>
		<td>Firewall rules are blocking connections from <%=vars.service_name_article_full%> broker to the service instance.</td>
		<td>Open the <%=vars.service_name%> tile in Ops Manager and check the two networks configured in the <strong>Networks</strong> pane. Ensure that these networks allow access to each other.</td>
	</tr>
	<tr>
		<td>Firewall rules are blocking connections from the service network to the BOSH director network.</td>
		<td>Ensure that service instances can access the Director so that the BOSH agents can report in.</td>
	</tr>
	<tr>
		<td>Apps cannot access the service network.</td>
		<td>Configure Cloud Foundry application security groups to allow runtime access to the service network.</td>
	</tr>
	<tr>
		<td>Problems accessing BOSH’s UAA or the BOSH director.</td>
		<td>Follow network troubleshooting and check that the BOSH director is online</td>
	</tr>
</table>
<a id="broker-to-instances"></a><h4>Validate Service Broker Connectivity to Service Instances</h4>

<p>
	To validate connectivity, do the following:
</p>

<ol>
	<li>
		<p>
			To SSH into <%=vars.service_name_article_full%>  broker, run the following command:
		</p>
		<pre><code>bosh -d service-instance_GUID ssh</code></pre>
	</li>
	<li>
		<p>
			If no BOSH <code>task-id</code> appears in the error message, look in the
			broker log using the <code>broker-request-id</code> from the task.
		</p>
	</li>
</ol>
<a id="app-to-instances"></a><h4>Validate App Access to Service Instance</h4>

<p>
  Use <code>cf ssh</code> to access to the app container, then try connecting to
  <%=vars.service_name_article_full%> instance using the binding included in the
  <code>VCAP_SERVICES</code> environment variable.
</p>
<a id="quotas"></a><h3>Quotas</h3>

<a id="plan-quotas"></a><h4>Plan Quota issues</h4>

<p>
  If developers report errors such as:
</p>

<pre class="terminal">
Message: Service broker error: The quota for this service plan has been exceeded.
Please contact your Operator for help.
</pre>

<ol>
  <li>Check your current plan quota.</li>
  <li>Increase the plan quota.</li>
  <li>Log into Ops Manager.</li>
  <li>Reconfigure the quota on the plan page.</li>
  <li>Deploy the tile.</li>
  <li>Find who is using the plan quota and take the appropriate action.</li>
</ol>
<a id="global-quotas"></a><h4>Global Quota Issues</h4>

<p>
  If developers report errors such as:
</p>

<pre class="terminal">
Message: Service broker error: The quota for this service has been exceeded.
Please contact your Operator for help.
</pre>

<ol>
  <li>Check your current global quota.</li>
  <li>Increase the global quota.</li>
  <li>Log into Ops Manager.</li>
  <li>Reconfigure the quota on the on-demand settings page.</li>
  <li>Deploy the tile.</li>
  <li>Find out who is using the quota and take the appropriate action.</li>
</ol>
<a id="failing-jobs"></a><h3>Failing Jobs and Unhealthy Instances</h3>

<p>
  To determine whether there is an issue with  <%= vars.service_name_article_full%>
  deployment, inspect the VMs. To do so, run the following command:
</p>

<pre><code>bosh -d service-instance_GUID vms --vitals</code></pre>

<p>
  For additional information, run the following command:
</p>

<pre><code>bosh instances --ps --vitals</code></pre>

<p>
  If the VM is failing, follow the service-specific information.
  Any unadvised corrective actions (such as running BOSH <code>restart</code> on
  a VM) can cause issues in the service instance.
</p>
A failing process or failing VM might come back automatically after a temporary service outage.
See <a href="./interruptions.html#process-fail">VM Process Failure</a> and
<a href="./interruptions.html#vm-fail">VM Failure</a>.

<a id="az-region-fail"></a><h3>AZ or Region Failure</h3>

Failures at the IaaS level, such as Availability Zone (AZ) or region  failures, can interrupt service and require manual restoration. See <a href="./interruptions.html#az-fail">AZ Failure</a>
and <a href="./interruptions.html#region-fail">Region Failure</a>.

<a id="techniques"></a><h2>Techniques for Troubleshooting</h2>

Instructions on interacting with the on-demand service broker and on-demand service instance BOSH deployments, and on performing general maintenance and housekeeping tasks

<a id="parse-error"></a><h3>Parse a Cloud Foundry (CF) Error Message</h3>

<p>
  Failed operations (create, update, bind, unbind, delete) result in an error message.
  You can retrieve the error message later by running the cf CLI command <code>cf service INSTANCE-NAME</code>.
</p>

<pre class="terminal">
$ cf service myservice

Service instance: myservice
Service: super-db
Bound apps:
Tags:
Plan: dedicated-vm
Description: Dedicated Instance
Documentation url:
Dashboard:

Last Operation
Status: create failed
Message: Instance provisioning failed: There was a problem completing your request.
     Please contact your operations team providing the following information:
     service: redis-acceptance,
     service-instance-guid: ae9e232c-0bd5-4684-af27-1b08b0c70089,
     broker-request-id: 63da3a35-24aa-4183-aec6-db8294506bac,
     task-id: 442,
     operation: create
Started: 2017-03-13T10:16:55Z
Updated: 2017-03-13T10:17:58Z
</pre>

<p>
  Use the information in the <code>Message</code> field to debug further.
  Provide this information to Pivotal Support when filing a ticket.
</p>

<p>
  The <code>task-id</code> field maps to the BOSH task ID.
  For more information on a failed BOSH task, use the <code>bosh task TASK-ID</code>.
</p>

<p>
  The <code>broker-request-guid</code> maps to the portion of the On-Demand Broker log
  containing the failed step.
  Access the broker log through your syslog aggregator, or access BOSH logs for
  the broker by typing <code>bosh logs broker 0</code>.
  If you have more than one broker instance, repeat this process for each instance.
</p>
<a id="bosh-cf-access"></a><h3>Access Broker and Instance Logs and VMs</h3>

<p>
  Before following the procedures below, log into the
  <a href="https://docs.pivotal.io/pivotalcf/cf-cli/getting-started.html">cf CLI</a> and the
  <a href="https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#prepare">BOSH CLI</a>.
</p>
<a id="access-broker"></a><h4>Access Broker Logs and VM(s)</h4>

<p>
	You can <a href="https://docs.pivotal.io/pivotalcf/customizing/troubleshooting.html#component_logs">access logs using Ops Manager</a>
	by clicking on the <strong>Logs</strong> tab in the tile and downloading the broker logs.
</p>

<p>
	To access logs using the BOSH CLI, do the following:
</p>

<ol>
	<li>
		<p>
			Identify the on-demand broker (ODB) deployment by running the following command:
		</p>
		<pre><code>bosh deployments</code></pre>
	</li>
	<li>
		<p>
			View VMs in the deployment by running the following command:
		</p>
		<pre><code>bosh -d DEPLOYMENT-NAME instances</code></pre>
	</li>
	<li>
		<p>
			SSH onto the VM by running the following command:
		</p>
		<pre><code>bosh -d service-instance_GUID ssh</code></pre>
	</li>
	<li>
		<p>
			Download the broker logs by running the following command:
		</p>
		<pre><code>bosh -d service-instance_GUID logs</code></pre>
	</li>
</ol>

<p>
	The archive generated by BOSH or Ops Manager includes the following logs:
</p>

<table class="nice">
	<th>Log Name</th>
	<th>Description</th>
	<tr>
		<td>broker.log</td>
		<td>Requests to the on-demand broker and the actions the broker performs
			while orchestrating the request (e.g. generating a manifest and calling BOSH).
			Start here when troubleshooting.</td>
	</tr>
	<tr>
		<td>broker_ctl.log</td>
		<td>Control script logs for starting and stopping the on-demand broker.</td>
	</tr>
	<tr>
		<td>post-start.stderr.log</td>
		<td>Errors that occur during post-start verification.</td>
	</tr>
	<tr>
		<td>post-start.stdout.log</td>
		<td>Post-start verification.</td>
	</tr>
	<tr>
		<td>drain.stderr.log</td>
		<td>Errors that occur while running the drain script.</td>
	</tr>
</table>
<a id="access-instance"></a><h4>Access Service Instance Logs and VMs</h4>

<ol>
	<li>
		<p>
			To target an individual service instance deployment, retrieve the GUID of your
			service instance with the following cf CLI command:
		</p>
		<pre><code>cf service MY-SERVICE --guid</code></pre>
	</li>
	<li>
		<p>
			To view VMs in the deployment, run the following command:
		</p>
		<pre><code>bosh -d DEPLOYMENT-NAME instances</code></pre>
	</li>
	<li>
		<p>
			To SSH into a VM, run the following command:
		</p>
		<pre><code>bosh -d service-instance_GUID ssh</code></pre>
	</li>
	<li>
		<p>
			To download the instance logs, run the following command:
		</p>
		<pre><code>bosh -d service-instance_GUID logs</code></pre>
	</li>
</ol>
<a id="broker-errands"></a><h3>Run Service Broker Errands to Manage Brokers and Instances</h3>

<p>
  From the BOSH CLI, you can run service broker errands that manage the service
  brokers and perform mass operations on the service instances that the brokers created.
  These service broker errands include:
</p>

<ul>
  <li>
    <p>
      <a href="#register-broker"><code>register-broker</code></a> registers a broker with the Cloud Controller
      and lists it in the Marketplace.
    </p>
  </li>
  <li>
    <p>
      <a href="#deregister-broker"><code>deregister-broker</code></a> deregisters a broker with the Cloud
      Controller and removes it from the Marketplace.
    </p>
  </li>
  <li>
    <p>
      <a href="#upgrade-all"><code>upgrade-all-service-instances</code></a> upgrades existing instances of
      a service to its latest installed version.
    </p>
  </li>
  <li>
    <p>
      <a href="#delete-all"><code>delete-all-service-instances</code></a> deletes all instances of service.
    </p>
  </li>
  <li>
    <p>
      <a href="#detect-orphans"><code>orphan-deployments</code></a> detects "orphan" instances that are
      running on BOSH but not registered with the Cloud Controller.
    </p>
  </li>
</ul>

<p>
  To run an errand, run the following command:
</p>

<pre><code>bosh -d DEPLOYMENT-NAME run-errand ERRAND-NAME</code></pre>

<p>
  For example:
</p>

<pre class="terminal">bosh -d my-deployment run-errand deregister-broker</pre>
<a id="register-broker"></a><h4>Register Broker</h4>

<p>
  The <code>register-broker</code> errand registers the broker with Cloud Controller and enables
  access to plans in the Marketplace.
  You should run this errand whenever the broker is re-deployed with new catalog metadata to
  update the Marketplace.
</p>

<p>
  Plans with disabled service access are only visible to admin Cloud Foundry
  users. Non-admin Cloud Foundry users, including Org Managers and Space Managers, cannot
  see these plans.
</p>

<h3>What the Errand Does</h3>

<p>
  The <code>register-broker</code> errand does the following:
</p>

<ol>
  <li>Registers the service broker with Cloud Controller.</li>
  <li>
    Enables service access for any plans that are enabled on the tile.
  </li>
  <li>Disables service access for any plans that are disabled on the tile.
  </li>
  <li>Does nothing for any plans that are set to manual on the tile.</li>
</ol>

<h3>How to Run the Errand</h3>

<p>  To run the errand:</p>
<ol>
  <li>Run the following command:

<pre><code>bosh -d DEPLOYMENT-NAME run-errand register-broker</code></pre>
  </li>
</ol>

<a id="deregister-broker"></a><h4>Deregister Broker</h4>

<p>
  This errand deregisters a broker from Cloud Foundry.
</p>

<p>
  The errand does the following:
</p>

<ul>
  <li>Deletes the service broker from Cloud Controller</li>
  <li>Fails if there are any service instances, with or without bindings</li>
</ul>

<p>Use the <a href="#delete-all">
  Delete All Service Instances errand</a> to delete any existing service instances.
</p>

<p>
  To run the errand, run the following command:
</p>

<pre><code>bosh -d DEPLOYMENT-NAME run-errand deregister-broker</code></pre>
<a id="upgrade-all"></a><h4>Upgrade All Service Instances</h4>

<p>
	When you make changes to the plan configuration, you should
	upgrade all <%=vars.service_name_article_full%> instances to the latest version of the plan.
</p>

<h3> What the Errand Does </h3>

<p>
	The <code>upgrade-all-service-instances</code> errand does the following:
</p>

<ol>
	<li>Collects all of the service instances that the on-demand broker has registered</li>
	<li>For each instance the errand does the following:
		<ol>
			<li>Issues an upgrade command to the on-demand broker</li>
			<li>Regenerates the service instance manifest based on the latest configuration from the tile</li>
			<li>Deploys the new manifest for the service instance</li>
			<li>Waits for this operation to complete, then proceeds to the next instance</li>
		</ol>
	</li>
	<li>Adds to a retry list any instances that have ongoing BOSH tasks at the time of upgrade</li>
	<li>Retries any instances in the retry list until all instances are upgraded</li>
</ol>

<p>
	If any instance fails to upgrade, the errand fails immediately.
	This prevents systemic problems from spreading to the rest of your service instances.
</p>

<h3> How to Run the Errand </h3>

<p>
	To run the errand:
</p>
<ol>
	<li>Do one of the following</li>

	<ul>
		<li>
			Select the errand in the <strong>Ops Manager Installation Dashboard</strong>
			on the <strong>Review Pending Changes</strong> page and
			then click <strong>Apply Changes</strong>.
		</li>
		<li>
			<p>
				Run the following command:
			</p>
			<pre><code>bosh -d DEPLOYMENT-NAME run-errand upgrade-all-service-instances</code></pre>
		</li>
	</ul>
</ol>
<a id="delete-all"></a><h4>Delete All Service Instances</h4>

<p>
  This errand uses the Cloud Controller API to delete all instances of your broker’s
  service offering in every Cloud Foundry org and space. It only deletes instances
  the Cloud Controller knows about.
  It does not delete orphan BOSH deployments.
</p>

<p class="note">
  <strong>Note</strong>: Orphan BOSH deployments do not correspond to a known service instance.
  While rare, orphan deployments can occur. Use the <code>orphan-deployments</code>
  errand to identify them.
</p>

<p>
  The <code>delete-all-service-instances</code> errand does the following:
</p>

<ol>
  <li>Unbinds all apps from the service instances.</li>
  <li>
    Deletes all service instances sequentially. Each service instance deletion includes:
    <ol>
      <li>Running any pre-delete errands</li>
      <li>Deleting the BOSH deployment of the service instance</li>
      <li>Removing any ODB-managed secrets from BOSH CredHub</li>
      <li>Checking for instance deletion failure, which results in the errand failing immediately</li>
    </ol>
  </li>
  <li>
    Determines whether any instances have been created while the errand was running.
    If new instances are detected, the errand returns an error.
    In this case, Pivotal recommends running the errand again.
  </li>
</ol>

<p class="note warning">
  <strong>Warning:</strong> Use extreme caution when running this errand.
  You should only use it when you want to totally destroy all of the on-demand service
  instances in an environment.
</p>

<p>
  To run the errand, run the following command:
</p>

<pre><code>bosh -d service-instance_GUID delete-deployment</code></pre>
<a id="detect-orphans"></a><h3>Detect Orphaned Service Instances</h3>

<p>
  A service instance is defined as "orphaned" when the BOSH deployment for the
  instance is still running, but the service is no longer registered in Cloud Foundry.
</p>

<p>
  The <code>orphan-deployments</code> errand collates a list of service deployments that have
  no matching service instances in Cloud Foundry and return the list to the operator.
  It is then up to the operator to remove the orphaned BOSH deployments.
</p>

<p>
  To run the errand, run the following command:
</p>

<pre><code>bosh -d DEPLOYMENT-NAME run-errand orphan-deployments</code></pre>

<p>
  <strong>If orphan deployments exist</strong>---The errand script does the following:
</p>

<ul>
  <li>Exit with exit code 10</li>
  <li>Output a list of deployment names under a <code>[stdout]</code> header</li>
  <li>Provide a detailed error message under a <code>[stderr]</code> header</li>
</ul>

<p>
  For example:
</p>

<pre class="terminal">
[stdout]
[{"deployment\_name":"service-instance\_80e3c5a7-80be-49f0-8512-44840f3c4d1b"}]

[stderr]
Orphan BOSH deployments detected with no corresponding service instance in Cloud Foundry. Before deleting any deployment it is recommended to verify the service instance no longer exists in Cloud Foundry and any data is safe to delete.

Errand 'orphan-deployments' completed with error (exit code 10)
</pre>

<p>
  These details will also be available through the BOSH <code>/tasks/</code> API endpoint for use in scripting:
</p>

<pre class="terminal">
$ curl 'https<span>:</span>//bosh-user:bosh-password@bosh-url:25555/tasks/task-id/output?type=result' | jq .
{
  "exit_code": 10,
  "stdout": "[{"deployment_name":"service-instance_80e3c5a7-80be-49f0-8512-44840f3c4d1b"}]\n",
  "stderr": "Orphan BOSH deployments detected with no corresponding service instance in Cloud Foundry. Before deleting any deployment it is recommended to verify the service instance no longer exists in Cloud Foundry and any data is safe to delete.\n",
  "logs": {
    "blobstore_id": "d830c4bf-8086-4bc2-8c1d-54d3a3c6d88d"
  }
}
</pre>

<p>
  <strong>If no orphan deployments exist</strong>---The errand script does the following:
</p>

<ul>
  <li>Exit with exit code 0</li>
  <li>Stdout will be an empty list of deployments</li>
  <li>Stderr will be <code>None</code></li>
</ul>

<pre class="terminal">
[stdout]
[]

[stderr]
None

Errand 'orphan-deployments' completed successfully (exit code 0)
</pre>

<p>
  <strong>If the errand encounters an error during running</strong>---The errand script does the following:
</p>

<ul>
  <li>Exit with exit 1</li>
  <li>Stdout will be empty</li>
  <li>Any error messages will be under stderr</li>
</ul>

<p>
  To clean up orphaned instances, run the following command on each instance:
</p>

<p class="note warning">
  <strong>WARNING: </strong> Running this command may leave IaaS resources in an unusable state.
</p>

<pre><code>bosh delete-deployment service-instance_SERVICE-INSTANCE-GUID</code></pre>
<a id="instance-creds"></a><h3>Retrieve Admin and Read-Only Admin Credentials for a Service Instance</h3>

To retrieve the admin and read-only admin credentials for a service instance from BOSH CredHub, perform the following steps:

<ol>
<li>Use the cf CLI to determine the GUID associated with the service instance for which you want to retrieve credentials.
    Run the following command:
    <pre><code>cf service SERVICE-INSTANCE --guid</code></pre>
    <br>
    Where <code>SERVICE-INSTANCE</code> is the name of the service instance.
    <br><Br>
    For example:
    <pre class="terminal">$ cf service my-service-instance --guid
    12345678-90ab-cdef-1234-567890abcdef</pre>
    If you do not know the name of the service instance, you can list service instances in the space with <code>cf services</code>.
</li>
<li>Perform the steps in <a href="https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#gather">Gather Credential and IP Address Information</a> and <a href="https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#ssh">SSH into Ops Manager</a> of <em>Advanced Troubleshooting with the BOSH CLI to SSH into the Ops Manager VM</em>.</li>
<li>From the Ops Manager VM, log in to your BOSH Director with the BOSH CLI. See <a href="https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#log-in">Log in to the BOSH Director</a> in <em>Advanced Troubleshooting with the BOSH CLI</em>.</li>
<li> If you have not yet created a UAA client for BOSH CredHub on your UAA server, perform the steps in <a href="prepare-tls.html#uaa">Create UAA Client</a>.</li>
<li>Set the API target of the CredHub CLI to your BOSH CredHub server.
    <br><br>
    Run the following command:
    <pre><code>credhub api https://BOSH-DIRECTOR:8844 --ca-cert=/var/tempest/workspaces/default/root_ca_certificate</code></pre>
    <br>
    Where <code>BOSH-DIRECTOR</code> is the IP address of the BOSH Director VM.
    <br><br>
    For example:
    <pre class="terminal">$ credhub api http<span>s:</span>//10.0.0.5:8844 --ca-cert=/var/tempest/workspaces/default/root_ca_certificate</pre>
</li>
<li> Log in to BOSH CredHub.
    <br><br>
    Run the following command:
    <pre><code>credhub login --client-name=credhub --client-secret=CLIENT-SECRET</code></pre>
    <br>
    Where <code>CLIENT-SECRET</code> is the client secret you set in step 9 of <a href="prepare-tls.html#uaa">Create UAA Client</a>.
    <br><br>
    For example:
    <pre class="terminal">$ credhub login \
        --client-name=credhub \
        --client-secret=abcdefghijklm123456789</pre>
</li>
<li> Use the CredHub CLI to retrieve the credentials.
    <ul><li> To retrieve the password for the admin user, run the following command:
        <pre><code>credhub get -n /p-bosh/service-instance_GUID/admin_password</code></pre>
        In the output, the password appears under <code>value</code>.</li>
        <br>
    <li> To retrieve the password for the read-only admin user, run the following command:
        <pre><code>credhub get -n /p-bosh/service-instance_GUID/read_only_admin_password</pre></code>
        In the output, the password appears under <code>value</code>.</li></ul>
    <br>
    For example:
    <pre class="terminal">$ credhub get -n /p-bosh/service-instance_70d30bb6-7f30-441a-a87c-05a5e4afff26/admin_password
    id: d6e5bd10-3b60-4a1a-9e01-c76da688b847
    name: /p-bosh/service-instance_70d30bb6-7f30-441a-a87c-05a5e4afff26/admin_password
    type: password
    value: UMF2DXsqNPPlCNWMdVMcNv7RC3Wi10
    version_created_at: 2018-04-02T23:16:09Z</pre>

<a id="reinstall"></a><h3>Reinstall a Tile</h3>

To reinstall the MySQL for PCF tile, see <a href="https://community.pivotal.io/s/article/Reinstalling-MySQL-for-Pivotal-Cloud-Foundry-version-2-and-above">Reinstalling MySQL for Pivotal Cloud Foundry version 2 and above</a> in the Pivotal Support knowledge base.

<a id="view-resources"></a><h3>View Resource Saturation and Scaling</h3>

<p>
	To view usage statistics for any service, do the following:
</p>

<ol>
	<li>
		<p>
			Run the following command:
		</p>
		<pre><code>bosh -d DEPLOYMENT-NAME vms --vitals</code></pre>
	</li>
	<li>
		<p>
			To view process-level information, run:
		</p>
		<pre><code>bosh -d DEPLOYMENT-NAME instances --ps</code></pre>
	</li>
</ol>
<a id="id-instance-owner"></a><h3>Identify Service Instance Owner</h3>

<p>
  If you want to identify which apps are using a specific service instance from the
  BOSH deployments name, do the following:
</p>

<ol>
  <li>Take the deployment name and strip the <code>service-instance_</code> leaving you with the GUID.</li>
  <li>Log in to CF as an admin.</li>
  <li>
    Obtain a list of all service bindings by running the following:
    <pre><code>cf curl /v2/service_instances/GUID/service_bindings</code></pre>
  </li>
  <li>
    The output from the above curl gives you a list of <code>resources</code>,
    with each item referencing a service binding, which contains the <code>APP-URL</code>.
    To find the name, org, and space for the app, run the following:
    <ol>
      <li><code>cf curl APP-URL</code> and record the app name under <code>entity.name</code>.</li>
      <li><code>cf curl SPACE-URL</code> to obtain the space, using the <code>entity.space_url</code>
        from the above curl.
        Record the space name under <code>entity.name</code>.
      </li>
      <li>
        <code>cf curl ORGANIZATION-URL</code> to obtain the org, using the
        <code>entity.organization_url</code> from the above curl.
        Record the organization name under <code>entity.name</code>.
      </li>
    </ol>
  </li>
</ol>

<p class="note">
  <strong>Note</strong>: When running <code>cf curl</code> ensure that you query
  all pages, because the responses are limited to a certain number of bindings per page.
    The default is 50.
    To find the next page curl the value under <code>next_url</code>.
</p>
<a id="monitor-quota"></a><h3>Monitor Quota Saturation and Service Instance Count</h3>

<p>
  Quota saturation and total number of service instances are available through ODB
  metrics emitted to Loggregator. The metric names are shown below:
</p>

<table>
  <thead>
    <tr>
      <th><strong>Metric Name</strong></th>
      <th><strong>Description</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>on-demand-broker/SERVICE-NAME-MARKETPLACE/quota_remaining</code></td>
      <td>global quota remaining for all instances across all plans</td>
    </tr>
    <tr>
      <td><code>on-demand-broker/SERVICE-NAME-MARKETPLACE/PLAN-NAME/quota_remaining</code></td>
      <td>quota remaining for a particular plan</td>
    </tr>
    <tr>
      <td><code>on-demand-broker/SERVICE-NAME-MARKETPLACE/total_instances</code></td>
      <td>total instances created across all plans</td>
    </tr>
    <tr>
      <td><code>on-demand-broker/SERVICE-NAME-MARKETPLACE/PLAN-NAME/total_instances</code></td>
      <td>total instances created for a given plan</td>
    </tr>
  </tbody>
</table>

<p class="note">
  <strong>Note</strong>: Quota metrics are not emitted if no quota has been set.
</p>
<a id="kb"></a><h2>Knowledge Base (Community)</h2>

<p>
  Find the answer to your question and browse product discussions and solutions by
  searching the <a href="https://community.pivotal.io/s/">Pivotal Knowledge Base</a>.
</p>
<a id="support"></a><h2>File a Support Ticket</h2>

<p>
  You can file a ticket with <a href="https://support.pivotal.io/">Pivotal Support</a>.
  Be sure to provide the error message from <code>cf service YOUR-SERVICE-INSTANCE</code>.
</p>

<p>
  To expedite troubleshooting, provide your service broker logs and your service instance logs.
  If your <code>cf service YOUR-SERVICE-INSTANCE</code> output includes a
  <code>task-id</code>, provide the BOSH task output.
</p>
