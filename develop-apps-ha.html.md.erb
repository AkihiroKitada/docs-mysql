---
title: Using HA Clusters
owner: MySQL
---

<strong><%= modified_date %></strong>

<%= partial "./galera_beta" %>

This topic describes how highly available (HA) clusters work in MySQL for Pivotal Cloud Foundry (PCF) and contains information about limitations for app developers.

## <a id="limitations"></a> Highly Available Cluster Limitations

HA clusters perform vaildations at startup and during runtime to prevent you from using MySQL features that are not supported. If you use HA clusters the following features are limited:

+ Data defintion lanaguge (DDL) and data manipulation lanaguge (DML) statements
+ 
+
+
+
+

If a validation fails during startup, the server is halted and throws an error. If a validation fails during runtime the operation is denied and throws an error.

PXC Strict Mode validations are designed to ensure optimal operation for common cluster setups that do not require experimental features and do not rely on operations not supported by Percona XtraDB Cluster.

- HA clusters only support the InnoDB storage engine. InnoDB is the default storage engine for new tables. Tables that are not using InnoDB are at risk because they are not replicated within a cluster.

- All tables must have a primary key. You can use multi-column primary keys. This is because HA clusters replicate using row based replication and ensure unique rows on each instance. 

- Explicit table locking is not supported. 

- By default,  are not sequential and each node has gaps in IDs. This prevents auto-increment replication conflicts across the cluster. For more infomation, see [wsrep\_auto\_increment\_control](https://www.percona.com/doc/percona-xtradb-cluster/LATEST/wsrep-system-index.html#wsrep_auto_increment_control) in the Percona XtraDB Cluster documentation. 
 
- HA clusters sets users to `READ ONLY` when using auto increment variables. This is because, otherwise HA clusters would require shared locking of the auto increment variables across the cluster, which causes it to be slower and less reliable. [TALK TO ANDREW]

- Large data defintion lanaguge (DDL) statements lock all schemas. This can be mitigated by using the Rolling Schema Upgrade (RSU) method. For more information about using RSU to apply DDL statements, see [Using Rolling Schema Upgrade](./rsu.html).

- Large transactions take a long time to replicate. This impacts apps that are using the cluster. To limit this impact, the maximum size that a node allows for DDL or DML statements is limted to 2GB. For more information, see [wsrep\_max\_ws\_size] (https://www.percona.com/doc/percona-xtradb-cluster/LATEST/wsrep-system-index.html#wsrep_max_ws_size) in the Percona XtraDB Cluster documentation. 
 
- In InnoDB, some transactions can cause deadlocks. You can minimize deadlocks in your apps by rewriting transactions and SQL statements. For more information about deadlocks, see [Deadlocks in InnoDB](http://dev.mysql.com/doc/refman/en/innodb-deadlocks.html) and [How to Minimize and Handle Deadlocks](http://dev.mysql.com/doc/refman/en/innodb-deadlocks-handling.html) in MySQL documentation. 





- Table partitioning can cause an hung state in the cluster. This is a result of the implicit table locks that are used when running table partition commands. [TALK TO ANDREW]



- MySQL for PCF does not support MySQL 5.7's JSON [TALK TO ANDREW]
