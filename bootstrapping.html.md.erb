---
title: Bootstrapping
owner: MySQL
---

This topic describes how to bootstrap your MySQL cluster in the event of a cluster failure.

## <a id="when-to-bootstrap"></a> When to Bootstrap ##

To determine whether you need to bootstrap your cluster, you must check whether the cluster has lost quorum. Bootstrapping is only required when the cluster has lost quorum. See [Check Cluster State](#check-state) for more information about checking the state of your cluster.

Quorum is lost when less than half of the nodes can communicate with each other for longer than the configured grace period. In Galera terminology, if a node can communicate with the rest of the cluster, its database is in a good state, and it reports itself as ```synced```.

If quorum has not been lost, individual unhealthy nodes should automatically rejoin the cluster once repaired, which means the error is resolved, the node is restarted, or connectivity is restored.

To check whether your cluster has lost quorum, look for the following symptoms:

- All nodes appear "Unhealthy" on the proxy dashboard, as in the following screenshot:
![3 out of 3 nodes are unhealthy.](quorum-lost.png)
- All responsive nodes report the value of `wsrep_cluster_status` as `non-Primary` in the MySQL client.

        mysql> SHOW STATUS LIKE 'wsrep_cluster_status';
        +----------------------+-------------+
        | Variable_name        | Value       |
        +----------------------+-------------+
        | wsrep_cluster_status | non-Primary |
        +----------------------+-------------+
- All unresponsive nodes respond with `ERROR 1047` when using most statement types in the MySQL client:

        mysql> select * from mysql.user;
        ERROR 1047 (08S01) at line 1: WSREP has not yet prepared node for application use

If your cluster has lost quorum, see the [Bootstrapping](bootstrapping.html) topic for information about manually bootstrapping a cluster.

Keep in mind the following:

- The start script bootstraps node 0 only on initial deploy. If bootstrapping is necessary at a later date, it must be done manually. 
- If the single node is bootstrapped, it creates a new one-node cluster that other nodes can join.

## <a id="bootstrapping"></a>Bootstrapping ##

Before running the bootstrapping procedures below, you must SSH into the Ops Manager VM and log in to the BOSH Director.

For more information, see [Prepare to Use the BOSH CLI](https://docs.pivotal.io/pivotalcf/1-10/customizing/trouble-advanced.html#prepare).

<p class="note"><strong>Note:</strong> The examples in these instructions reflect a three-node MySQL for Pivotal Cloud Foundry (PCF) deployment. The process to bootstrap a two-node plus an arbitrator is identical, but the output will not match the examples.</p>

### <a id="assisted-bootstrap"></a>Assisted Bootstrap ###

MySQL for PCF v1.8.0 and later include a [BOSH errand](http://bosh.io/docs/jobs.html#jobs-vs-errands) to automate the process of bootstrapping. It is still necessary to manually initiate the bootstrap process, but using this errand reduces the number of manual steps necessary to complete the process.

In most cases, running the errand is sufficient, however there are some conditions which require additional steps.

#### <a id="how-it-works"></a>How It Works ####

The bootstrap errand simply automates the steps in the manual bootstrapping process documented below. It finds the node with the highest transaction sequence number, and asks it to start up by itself (i.e. in bootstrap mode), then asks the remaining nodes to join the cluster.

### <a id="cluster-disrupted"></a>Scenario 1: Virtual Machines Running, Cluster Disrupted ###

In this scenario, the nodes are up and running, but the cluster has been disrupted.

To determine whether the cluster has been disrupted, perform the following steps:

1. Use `bosh vms` to list the jobs and see if they are `failing`. The output will resemble the following:

    <pre class="terminal">
    +--------------------------------------------------+---------+------------------------------------------------+------------+
    | Instance                                         | State   | Resource Pool                                  | IPs        |
    +--------------------------------------------------+---------+------------------------------------------------+------------+
    | cf-mysql-broker-partition-a813339fde9330e9b905/0 | running | cf-mysql-broker-partition-a813339fde9330e9b905 | 192.0.2.61 |
    | cf-mysql-broker-partition-a813339fde9330e9b905/1 | running | cf-mysql-broker-partition-a813339fde9330e9b905 | 192.0.2.62 |
    | mysql-partition-a813339fde9330e9b905/0           | failing | mysql-partition-a813339fde9330e9b905           | 192.0.2.55 |
    | mysql-partition-a813339fde9330e9b905/1           | failing | mysql-partition-a813339fde9330e9b905           | 192.0.2.56 |
    | mysql-partition-a813339fde9330e9b905/2           | failing | mysql-partition-a813339fde9330e9b905           | 192.0.2.57 |
    | proxy-partition-a813339fde9330e9b905/0           | running | proxy-partition-a813339fde9330e9b905           | 192.0.2.59 |
    | proxy-partition-a813339fde9330e9b905/1           | running | proxy-partition-a813339fde9330e9b905           | 192.0.2.60 |
    +--------------------------------------------------+---------+------------------------------------------------+------------+
    </pre>
1. If the jobs are failing, perform the following steps:
    1. Use `bosh deployment` to select the correct deployment.
    1. Use `bosh run errand bootstrap` to run the bootstrap errand.
    <br><br>
    You see many lines of output, eventually followed by:
    <pre class="terminal">
    Bootstrap errand completed
    [stderr]
    \+ echo 'Started bootstrap errand ...'
    \+ JOB_DIR=/var/vcap/jobs/bootstrap
    \+ CONFIG_PATH=/var/vcap/jobs/bootstrap/config/config.yml
    \+ /var/vcap/packages/bootstrap/bin/cf-mysql-bootstrap -configPath=/var/vcap/jobs/bootstrap/config/config.yml
    \+ echo 'Bootstrap errand completed'
    \+ exit 0
    Errand `bootstrap' completed successfully (exit code 0)
    </pre>
    If the bootstrap errand doesn't work immediately, wait and try it again a few minutes later.

### <a id="vms-terminated"></a>Scenario 2: Virtual Machines Terminated or Lost ###

In more severe circumstances, such as power failure, all of your VMs might have been lost. 
You must recreate them before you can begin to recover the cluster. 
In this scenario, the nodes appear as `unknown/unknown` in the output of `bosh vms`.

Run the BOSH CLI command `bosh vms`. The output will resemble the following:

<pre class="terminal">
+--------------------------------------------------+--------------------+------------------------------------------------+------------+
| Instance                                         | State              | Resource Pool                                  | IPs        |
+--------------------------------------------------+--------------------+------------------------------------------------+------------+
| unknown/unknown                                  | unresponsive agent |                                                |            |
+--------------------------------------------------+--------------------+------------------------------------------------+------------+
| unknown/unknown                                  | unresponsive agent |                                                |            |
+--------------------------------------------------+--------------------+------------------------------------------------+------------+
| unknown/unknown                                  | unresponsive agent |                                                |            |
+--------------------------------------------------+--------------------+------------------------------------------------+------------+
| cf-mysql-broker-partition-e97dae91e44681e0b543/0 | running            | cf-mysql-broker-partition-e97dae91e44681e0b543 | 192.0.2.65 |
| cf-mysql-broker-partition-e97dae91e44681e0b543/1 | running            | cf-mysql-broker-partition-e97dae91e44681e0b543 | 192.0.2.66 |
+--------------------------------------------------+--------------------+------------------------------------------------+------------+
| proxy-partition-e97dae91e44681e0b543/0           | running            | proxy-partition-e97dae91e44681e0b543           | 192.0.2.63 |
| proxy-partition-e97dae91e44681e0b543/1           | running            | proxy-partition-e97dae91e44681e0b543           | 192.0.2.64 |
+--------------------------------------------------+--------------------+------------------------------------------------+------------+
</pre>

#### <a id="vm-recovery"></a>Recover Terminated or Lost VMs ####

To recover your VMs, perform the following steps:

1. If you use the [VM Resurrector](http://docs.pivotal.io/pivotalcf/customizing/resurrector.html#enabling), disable it.
1. Run the BOSH Cloud Check interactive command.
Use the BOSH CLI command `bosh cck`.
    <br><br>
    When prompted, select **Recreate VM**. If this option fails, select **Delete VM reference**.
    <br><br>
    The output will resemble the following:
    <pre class="terminal">
    Acting as user 'director' on deployment 'cf-e82cbf44613594d8a155' on 'p-bosh-30c19bdd43c55c627d70'
    Performing cloud check...

    Director task 34
    Started scanning 22 vms
    Started scanning 22 vms > Checking VM states. Done (00:00:10)
    Started scanning 22 vms > 19 OK, 0 unresponsive, 3 missing, 0 unbound, 0 out of sync. Done (00:00:00)
    Done scanning 22 vms (00:00:10)

    Started scanning 10 persistent disks
    Started scanning 10 persistent disks > Looking for inactive disks. Done (00:00:02)
    Started scanning 10 persistent disks > 10 OK, 0 missing, 0 inactive, 0 mount-info mismatch. Done (00:00:00)
    Done scanning 10 persistent disks (00:00:02)

    Task 34 done

    Started   2015-11-26 01:42:42 UTC
    Finished  2015-11-26 01:42:54 UTC
    Duration  00:00:12

    Scan is complete, checking if any problems found.

    Found 3 problems

    Problem 1 of 3: VM with cloud ID `i-afe2801f' missing.
    1. Skip for now
    2. Recreate VM
    3. Delete VM reference
    Please choose a resolution [1 - 3]: 2

    Problem 2 of 3: VM with cloud ID `i-36741a86' missing.
    1. Skip for now
    2. Recreate VM
    3. Delete VM reference
    Please choose a resolution [1 - 3]: 2

    Problem 3 of 3: VM with cloud ID `i-ce751b7e' missing.
    1. Skip for now
    2. Recreate VM
    3. Delete VM reference
    Please choose a resolution [1 - 3]: 2
    </pre>
1. Re-enable the VM Resurrector if you want to continue to use it.

Do not proceed to the next step until all three VMs are in the `starting` or `failing` state.

#### <a id="updating-manifest"></a>Update the BOSH Configuration ####

In a standard deployment, BOSH is configured to manage the cluster in a specific manner.
You must change that configuration in order for the bootstrap errand to perform its work.

Perform the following steps:

1. Log in to the BOSH Director.
1. Target the correct deployment.
1. Run `bosh edit deployment`:
    * Locate the `jobs.mysql-partition.update` section.
    * Change `max_in_flight` to `3`.
    * Below the `max_in_flight` line, add a line: `canaries: 0`.
1. Run `bosh deploy`.

#### <a id="run-the-errand"></a>Run the Bootstrap Errand ####

1. Run the BOSH CLI command `bosh run errand bootstrap`.

1. Validate that the errand completes successfully. Even if some instances still appear as `failing`,
   proceed to the next step.

#### <a id="reset-deployment"></a>Restore the BOSH Configuration ####

To restore your BOSH configuration to its previous state, follow the previous steps
from [Update the BOSH Configuration](#updating-manifest) and use the following values:

* Set `canaries` to `1`.
* Set `max_in_flight` to `1`.
* Set `serial` to `true` in the same manner as above.

After updating the BOSH configuration, perform the following steps:

1. Redeploy your BOSH Director.
1. Validate that all `mysql` instances are in `running` state.

<p class="note"><strong>Note:</strong> You must run all of the steps. If you do not re-set the values in the BOSH manifest,
the status of the jobs is not reported correctly and can lead to problems with future deploys.</p>

---

## <a id="manual-bootstrap"></a>Manual Bootstrap ##

If the bootstrap errand is not able to automatically recover the cluster,
you might need to perform the steps manually. 

<p class="note warning"><strong>WARNING</strong>: The following procedures are prone to user-error
   and can result in lost data if followed incorrectly.
   Follow the assisted bootstrap procedure in <a href="#bootstrapping">Bootstrapping</a> above first,
   and only resort to the manual process if the errand fails to repair the cluster.</p>

Perform the procedures in the sections below to manually bootstrap your cluster.

### <a id="shut-down-mariadb"></a>Shut Down MariaDB

Perform the following steps for each node in the cluster:

1. SSH into the node.
   For more information about how to SSH into BOSH-deployed VMs,
   see [BOSH SSH](https://docs.pivotal.io/pivotalcf/1-10/customizing/trouble-advanced.html#bosh-ssh).
1. Shut down the `mariadb` process on the node. 
Run the following command:

    ```
    monit stop mariadb_ctrl
    ```

Re-bootstrapping the cluster is not successful unless you shut down the `mariadb` process on all nodes in the cluster.

### <a id="choose-node"></a> Choose Node to Bootstrap 

To choose the node to bootstrap, you must find the node with the highest transaction sequence number (`seqno`).

Perform the following steps to find the node with the highest `seqno`:

1. Run the following command from the node:
            
    ```
    cat /var/vcap/store/mysql/grastate.dat | grep 'seqno:'
    ```
1. If a node shut down gracefully, the `seqno` is in the Galera state file. 
Retrieve the `seqno` and continue to [Bootstrap the First Node](#set-bootstrap-node). 
<br><br>
If a node crashed or was killed, the `seqno` in the Galera state file is recorded as `-1`.
In this case, the `seqno` might be recoverable from the database. 
Run the following command to start up the database, log the recovered `seqno`, and then exit:

    ```
    /var/vcap/packages/mariadb/bin/mysqld --wsrep-recover
    ```

    Scan the error log for the recovered `seqno`. It is the last number after the group id (`uuid`). For example:

    <pre class="terminal">
    $ grep "Recovered position" /var/vcap/sys/log/mysql/mysql.err.log | tail -1
    150225 18:09:42 mysqld_safe WSREP: Recovered position e93955c7-b797-11e4-9faa-9a6f0b73eb46:15
    </pre>
    If the node never connected to the cluster before crashing,
    it may not even have a group id (`uuid` in `grastate.dat`).
    In this case, there is nothing to recover. Unless all nodes crashed this way, do not choose this node for bootstrapping.

1. After determining the `seqno` for all nodes in your cluster, identify the node with the highest `seqno`.
   If all nodes have the same `seqno`, you can choose any node as the new bootstrap node.

### <a id="set-bootstrap-node"></a>Bootstrap the First Node ###

After determining the node with the highest `seqno`, perform the following steps to bootstrap the node:

<p class="note"><strong>Note:</strong> Only perform these bootstrap commands on the node with the highest <code>seqno</code>.
   Otherwise the node with the highest <code>seqno</code> is unable to join the new cluster unless its data is abandoned.
   Its <code>mariadb</code> process will exit with an error. 
   For more information about intentionally abandoning data, see <a href="architecture.html">Architecture</a>.</p>

1. On the new bootstrap node, update the state file and restart the <code>mariadb</code> process. 
Run the following commands:

    <pre><code>echo -n "NEEDS_BOOTSTRAP" > /var/vcap/store/mysql/state.txt
    monit start mariadb_ctrl</code></pre>

1. It can take up to ten minutes for <code>monit</code> to start the <code>mariadb</code> process.
   To check if the <code>mariadb</code> process has started successfully, run the following command:

    <pre><code>watch monit summary</code></pre>

### <a id="restart-nodes"></a>Restart Remaining Nodes ###

1. After the bootstrapped node is running, start the <code>mariadb</code> process on the remaining nodes with <code>monit</code>. 
From the bootstrap node, run the following command:

    <pre><code>monit start mariadb_ctrl</code></pre>

    If the node is prevented from starting by the [Interruptor](interruptor.html),
    perform the manual procedure to force the node to rejoin the cluster,
    documented in [Pivotal Knowledge Base](https://discuss.pivotal.io/hc/en-us/articles/115014258668). 

    <p class="note warning"><strong>WARNING</strong>: Forcing a node to rejoin the cluster is a destructive procedure.
       Only perform it with the assistance of <a href="https://support.pivotal.io">Pivotal Support</a>.</p>

1. If the `monit start` command fails, it might be because the node with the highest `seqno` is `mysql/0`.
   In this case, perform the following steps:
    1. From the Ops Manager VM, run the following command to make BOSH ignore updating `mysql/0`:

        ```
        bosh ignore mysql/0
        ```

    1. Navigate to Ops Manager in a browser, log in, and click **Apply Changes**.
    1. When the deploy finishes, run the following command from the Ops Manager VM:

        ```
        bosh unignore mysql/0
        ```

1. Verify that the new nodes have successfully joined the cluster. 
SSH into the bootstrap node and run the following command to output the total number of nodes in the cluster:

    <pre><code>mysql> SHOW STATUS LIKE 'wsrep_cluster_size';</code></pre>
